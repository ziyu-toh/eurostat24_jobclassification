{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.retrievers import BM25Retriever, EnsembleRetriever\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain_community.embeddings import HuggingFaceBgeEmbeddings\n",
    "from langchain_community.vectorstores.faiss import DistanceStrategy\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "jobs_ts = pd.read_csv('../output/jobs_ts.csv')\n",
    "isco = pd.read_csv('../data/wi_labels.csv', dtype=str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some last minute cleaning\n",
    "jobs_ts['title_desc_ts_postclean'] = jobs_ts['title_desc_ts_postclean'].str.lower()\n",
    "isco['description'] = isco['description'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking out notes/Some related occupations classified elsewhere” for ISCO\n",
    "# These additional notes may end up saying how another classification would be better, and may confuse the rag\n",
    "# so to remove them. Note, \"notes\" are always after \"some related occupations...\"\n",
    "isco['description'] = (isco['description']\n",
    "                       .str.replace(r'(notes\\n.*)', '', regex=True)\n",
    "                       .str.replace(r'(some related occupations classified elsewhere.*)', '', regex=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking out notes/Some related occupations classified elsewhere” for ISCO\n",
    "# These additional notes may end up saying how another classification would be better, and may confuse the rag\n",
    "# so to remove them. Note, \"notes\" are always after \"some related occupations...\"\n",
    "isco['description'] = (isco['description']\n",
    "                       .str.replace(r'(notes\\n.*)', '', regex=True)\n",
    "                       .str.replace(r'(some related occupations classified elsewhere.*)', '', regex=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Creating gold standard based on the recommendations made in previous models\n",
    "\"\"\"\n",
    "The whole idea for this part is so that we can have a sensing of what could be some sources of error, and of course having\n",
    "to evaluate quality of responses without having to create a submission since we only have 10 submission attempts\n",
    "Evaluation below was done for baseline bge-large v1.5\n",
    "\n",
    "Conclusion:\n",
    "Employment agents and contractors (3333) comes up a lot, possibly because of all the miscellaneous/non-JD related text e.g. APPLY Save Follow us Site language Magyar English About us Download our mobile application Profession Offers for employers Imprint International services Have a question Customer service Contact Terms and Conditions Terms of use Privacy Policy Profession 2021 All Rights Reserved. Login To save a job To save a job, enter your e-mail address or log in to your profile Forgot your password Login I will send it to myself Login with Facebook Login with Google account\n",
    "keyword based approach may be useful and augmented onto this step\n",
    "Romanian/bulgarian/lithuanian job descriptions seem quite problematic. A lot of misc stuff from websites/about HR company who's managing the job post. To confirm if this is the case\n",
    "\n",
    "Need to remove \"Some related occupations classified elsewhere\" for isco dataset, without removing the notes after it. (Or may to consider removing the notes too, need to check first)\n",
    "\n",
    "* 897858836 and 771344098 were not graded as there were 0 hints on the type of jobs they were -- just gibberish\n",
    "\"\"\"\n",
    "\n",
    "# Filtering just to the sampled, and gold standard isco codes\n",
    "best_isco_dict = {\"872828466\":\"7132\",\n",
    "                  \"839465958\":\"2330\", # is grade 7-9 secondary school? or high school. 2320 seems plausible too\n",
    "                  \"857077872\":\"2212\", # consultants = specialists. maybe it doesn't understand that\n",
    "                  \"804595650\":\"2153\", # Best guess, but JD was not descriptive at all\n",
    "                  \"785637891\":\"2634\", # Not very descriptive JD\n",
    "                  \"843263945\":\"5223\",\n",
    "                  \"822053239\":\"7523\", # uninformative JD, text looks like buttons from a website\n",
    "                  \"823300143\":\"3334\", # Not very informative, but highlights real estate multiple times\n",
    "                  \"834972267\":\"8322\", # JD says car or bus driver. so 8322 or 8331 could be correct.\n",
    "                  \"793505712\":\"2514\",\n",
    "                  \"766940573\":\"5113\",\n",
    "                  \"830014473\":\"5223\", # Was none of the top 3. 2434 (top label) is wholesale, not retail\n",
    "                  \"792868203\":\"9629\", # Not descriptive at all. \n",
    "                  \"844673659\":\"8211\", # Not very descriptive, ambiguous JD\n",
    "                  \"824883616\":\"3434\", # Literally no description\n",
    "                  \"891827176\":\"2431\", # Big differences between the numbers. But it's more admin than the ISCO job description. maybe there will be a better suggestion next\n",
    "                  \"753741043\":\"7322\",\n",
    "                  \"776400501\":\"8142\", # Chemicals  vs plastics? Confused? maybe need keyword search?\n",
    "                  \"789188547\":\"2262\",\n",
    "                  \"848225359\":\"1345\", # Big differences between the numbers\n",
    "                  \"879064773\":\"9111\", # 9111, hard to say which one. 9111 is the first pick tho, although 5152 seems slightly more relevant. It depends on the skill level, which is not quite stated in the JD\n",
    "                  \"775359643\":\"2433\", # None of the 3 options were good. Too much focus on the business\n",
    "                  \"810131612\":\"7221\",\n",
    "                  \"802436242\":\"7411\", # No description of job\n",
    "                  \"754636130\":\"3321\",\n",
    "                  \"779195013\":\"5131\", # Very messy JD, has a lot of other jobs combined into 1.Mentions many diff countries, so maybe that's why 4221 (Travel consultants and clerks) came up tops\n",
    "                  \"799557704\":\"3112\", # JD was different from the job title. That being said, civil engineering was mentioned quite a bit, in terms of buildings and blueprints etc\n",
    "                  \"844474920\":\"9412\", # Only had job title!! the whole description was about the HR company. The only hint was \"unskilled\"\n",
    "                  \"872195174\":\"2151\", # Non-descriptive, had to rely on isco hierarchy, seemed like a proper engineer instead of a technician\n",
    "                  \"836929936\":\"8152\", # Close fight between 8152/8153, but 8152 seems all emcompassing\n",
    "                  \"887356686\":\"9333\", # Totally wrong. Perhaps due to a technical terminology e.g. dock, and CACES\n",
    "                  \"877325404\":\"4222\",\n",
    "                  \"794441431\":\"7111\", # Not very descriptive. Not likely a supervisory role, hence 7111 instead of 3123\n",
    "                  \"891808036\":\"9321\", # Only have job title\n",
    "                  \"847941059\":\"5322\",\n",
    "                  \"786885741\":\"2431\", # No tasks at all, only talks about the company. 2431 was the closest\n",
    "                  \"873295233\":\"3322\",\n",
    "                  \"845150846\":\"2152\",\n",
    "                  \"779705693\":\"9412\",\n",
    "                  \"797628595\":\"9112\", # 9129 might be better than 9112 due to it mentioning usage of machinery, which is slightly more special. Stick to 9112 for now\n",
    "                  \"828908699\":\"2141\", # Was tough finding a job description for QA/QC. Maybe a better classification will come along\n",
    "                  \"863016564\":\"5244\" # Most likely, but non-descriptive JD too.                 \n",
    "                  \n",
    "                  } \n",
    "\n",
    "jobs_ts = jobs_ts[jobs_ts['id'].astype(str).isin(best_isco_dict.keys())].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embeddings\n",
    "model_name = \"BAAI/bge-large-en-v1.5\"\n",
    "model_kwargs = {\"device\": \"cpu\",}\n",
    "encode_kwargs = {\"normalize_embeddings\": False}\n",
    "hf = HuggingFaceBgeEmbeddings(\n",
    "    model_name=model_name, \n",
    "    model_kwargs=model_kwargs, \n",
    "    encode_kwargs=encode_kwargs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up lists for later\n",
    "doc_list = isco['description'].to_list()\n",
    "code_dict_list = [{\"code\":code} for code in isco['code']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the bm25 retriever and faiss retriever\n",
    "\n",
    "# Initialize the stemmer and stop words list\n",
    "stemmer = PorterStemmer()\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "k=10\n",
    "def bm25_preproc_function(text):\n",
    "   return ' '.join([stemmer.stem(word) for word in word_tokenize(text) if word.isalnum() and word not in stop_words])\n",
    "\n",
    "bm25_retriever = BM25Retriever.from_texts(doc_list, \n",
    "                                 #         preprocess_func=bm25_preproc_function,\n",
    "                                          metadatas = code_dict_list\n",
    "                                          ) # Needs lowercasing, stopword removal, stemming.. to\n",
    "bm25_retriever.k = k\n",
    "\n",
    "faiss_vectorstore = FAISS.from_texts(doc_list, \n",
    "                                     hf, \n",
    "                                     distance_strategy=DistanceStrategy.COSINE,\n",
    "                                     metadatas = code_dict_list)\n",
    "faiss_retriever = faiss_vectorstore.as_retriever(search_kwargs={\"k\": k})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_lca(row):\n",
    "    isco1 = row['manual_isco']\n",
    "    isco2 = row['isco_code']\n",
    "    print(isco1)\n",
    "    print(isco2)\n",
    "    if isco1[0] != isco2[0]:\n",
    "        return 0\n",
    "    elif isco1[1] != isco2[1]:\n",
    "        return 0.25\n",
    "    elif isco1[2] != isco2[2]:\n",
    "        return 0.5\n",
    "    elif isco1[3] != isco2[3]:\n",
    "        return 0.75\n",
    "    else:\n",
    "        return 1\n",
    "\n",
    "def calc_lca_df(df):\n",
    "    eval_df = df[df['id'].astype(str).isin(best_isco_dict.keys())].copy()\n",
    "    eval_df['manual_isco'] = eval_df['id'].astype(str).map(best_isco_dict)\n",
    "    eval_df['lca'] = eval_df.apply(calc_lca, axis=1)\n",
    "    avg_lca = eval_df['lca'].mean()\n",
    "    print(f\"Avg LCA: {avg_lca}\") \n",
    "    return avg_lca\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the ensemble retriever\n",
    "faiss_wts = np.arange(0, 1 + 0.1, 0.1)\n",
    "lca_score_list = []\n",
    "for faiss_wt in faiss_wts:\n",
    "    print('FAISS Weight: ', faiss_wt)\n",
    "    # Set up hybrid retriever\n",
    "    ensemble_retriever = EnsembleRetriever(retrievers=[bm25_retriever, faiss_retriever],\n",
    "                                           weights=[1-faiss_wt, faiss_wt])\n",
    "    \n",
    "    # For each description, get relevant documents, take the first ranked document, and also the code \n",
    "    top_doc_list = []\n",
    "    top_code_list = []\n",
    "    for desc in jobs_ts['title_desc_ts_postclean']:\n",
    "        docs = ensemble_retriever.get_relevant_documents(desc)\n",
    "        top_doc_list.append(docs[0])\n",
    "        top_code_list.append(docs[0].metadata['code'])\n",
    "        \n",
    "    # Calculate\n",
    "    jobs_ts['isco_code'] = top_code_list\n",
    "    lca_score_list.append(calc_lca_df(jobs_ts))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot: Hybrid doesn't seem to help in this case\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(faiss_wts, lca_score_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "es24",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
