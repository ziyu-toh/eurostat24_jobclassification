{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModel\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import gc\n",
    "import torch\n",
    "\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "jobs_ts = pd.read_csv('../output/jobs_ts_cleaned_regex.csv') # jobs_ts_cleaned_regex, jobs_ts_cleaned_simsearch_regex\n",
    "isco = pd.read_csv('../data/wi_labels.csv', dtype=str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose from: title_desc_ts_postclean_regex_simsearch (in jobs_ts_cleaned_simsearch_regex), \n",
    "# title_desc_ts_postclean_regex (in jobs_ts_cleaned_regex), title_desc_ts_postclean (in jobs_ts_cleaned_regex)\n",
    "jd_colname = \"title_desc_ts_postclean\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some last minute cleaning\n",
    "isco['description'] = isco['description'].str.lower()\n",
    "\n",
    "# Checking out notes/Some related occupations classified elsewhere‚Äù for ISCO\n",
    "# These additional notes may end up saying how another classification would be better, and may confuse the rag\n",
    "# so to remove them. Note, \"notes\" are always after \"some related occupations...\"\n",
    "isco['description'] = (isco['description']\n",
    "                       .str.replace(r'(notes\\n.*)', '', regex=True)\n",
    "                       .str.replace(r'(some related occupations classified elsewhere.*)', '', regex=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create query (the jd) and document (isco) lists\n",
    "jd = jobs_ts[jd_colname].to_list()\n",
    "isco_desc = isco['description'].to_list()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Creating gold standard based on the recommendations made in previous models\n",
    "\"\"\"\n",
    "The whole idea for this part is so that we can have a sensing of what could be some sources of error, and of course having\n",
    "to evaluate quality of responses without having to create a submission since we only have 10 submission attempts\n",
    "Evaluation below was done for baseline bge-large v1.5\n",
    "\n",
    "Conclusion:\n",
    "Employment agents and contractors (3333) comes up a lot, possibly because of all the miscellaneous/non-JD related text e.g. APPLY Save Follow us Site language Magyar English About us Download our mobile application Profession Offers for employers Imprint International services Have a question Customer service Contact Terms and Conditions Terms of use Privacy Policy Profession 2021 All Rights Reserved. Login To save a job To save a job, enter your e-mail address or log in to your profile Forgot your password Login I will send it to myself Login with Facebook Login with Google account\n",
    "keyword based approach may be useful and augmented onto this step\n",
    "Romanian/bulgarian/lithuanian job descriptions seem quite problematic. A lot of misc stuff from websites/about HR company who's managing the job post. To confirm if this is the case\n",
    "\n",
    "Need to remove \"Some related occupations classified elsewhere\" for isco dataset, without removing the notes after it. (Or may to consider removing the notes too, need to check first)\n",
    "\n",
    "* 897858836 and 771344098 were not graded as there were 0 hints on the type of jobs they were -- just gibberish\n",
    "\"\"\"\n",
    "\n",
    "# Filtering just to the sampled, and gold standard isco codes\n",
    "best_isco_dict = {\"872828466\":\"7132\",\n",
    "                  \"839465958\":\"2330\", # is grade 7-9 secondary school? or high school. 2320 seems plausible too\n",
    "                  \"857077872\":\"2212\", # consultants = specialists. maybe it doesn't understand that\n",
    "                  \"804595650\":\"2153\", # Best guess, but JD was not descriptive at all\n",
    "                  \"785637891\":\"2634\", # Not very descriptive JD\n",
    "                  \"843263945\":\"5223\",\n",
    "                  \"822053239\":\"7523\", # uninformative JD, text looks like buttons from a website\n",
    "                  \"823300143\":\"3334\", # Not very informative, but highlights real estate multiple times\n",
    "                  \"834972267\":\"8322\", # JD says car or bus driver. so 8322 or 8331 could be correct.\n",
    "                  \"793505712\":\"2514\",\n",
    "                  \"766940573\":\"5113\",\n",
    "                  \"830014473\":\"5223\", # Was none of the top 3. 2434 (top label) is wholesale, not retail\n",
    "                  \"792868203\":\"9629\", # Not descriptive at all. \n",
    "                  \"844673659\":\"8211\", # Not very descriptive, ambiguous JD\n",
    "                  \"824883616\":\"3434\", # Literally no description\n",
    "                  \"891827176\":\"2431\", # Big differences between the numbers. But it's more admin than the ISCO job description. maybe there will be a better suggestion next\n",
    "                  \"753741043\":\"7322\",\n",
    "                  \"776400501\":\"8142\", # Chemicals  vs plastics? Confused? maybe need keyword search?\n",
    "                  \"789188547\":\"2262\",\n",
    "                  \"848225359\":\"1345\", # Big differences between the numbers\n",
    "                  \"879064773\":\"9111\", # 9111, hard to say which one. 9111 is the first pick tho, although 5152 seems slightly more relevant. It depends on the skill level, which is not quite stated in the JD\n",
    "                  \"775359643\":\"2433\", # None of the 3 options were good. Too much focus on the business\n",
    "                  \"810131612\":\"7221\",\n",
    "                  \"802436242\":\"7411\", # No description of job\n",
    "                  \"754636130\":\"3321\",\n",
    "                  \"779195013\":\"5131\", # Very messy JD, has a lot of other jobs combined into 1.Mentions many diff countries, so maybe that's why 4221 (Travel consultants and clerks) came up tops\n",
    "                  \"799557704\":\"3112\", # JD was different from the job title. That being said, civil engineering was mentioned quite a bit, in terms of buildings and blueprints etc\n",
    "                  \"844474920\":\"9412\", # Only had job title!! the whole description was about the HR company. The only hint was \"unskilled\"\n",
    "                  \"872195174\":\"2151\", # Non-descriptive, had to rely on isco hierarchy, seemed like a proper engineer instead of a technician\n",
    "                  \"836929936\":\"8152\", # Close fight between 8152/8153, but 8152 seems all emcompassing\n",
    "                  \"887356686\":\"9333\", # Totally wrong. Perhaps due to a technical terminology e.g. dock, and CACES\n",
    "                  \"877325404\":\"4222\",\n",
    "                  \"794441431\":\"7111\", # Not very descriptive. Not likely a supervisory role, hence 7111 instead of 3123\n",
    "                  \"891808036\":\"9321\", # Only have job title\n",
    "                  \"847941059\":\"5322\",\n",
    "                  \"786885741\":\"2431\", # No tasks at all, only talks about the company. 2431 was the closest\n",
    "                  \"873295233\":\"3322\",\n",
    "                  \"845150846\":\"2152\",\n",
    "                  \"779705693\":\"9412\",\n",
    "                  \"797628595\":\"9112\", # 9129 might be better than 9112 due to it mentioning usage of machinery, which is slightly more special. Stick to 9112 for now\n",
    "                  \"828908699\":\"2141\", # Was tough finding a job description for QA/QC. Maybe a better classification will come along\n",
    "                  \"863016564\":\"5244\" # Most likely, but non-descriptive JD too.                 \n",
    "                  } \n",
    "\n",
    "jobs_ts = jobs_ts[jobs_ts['id'].astype(str).isin(best_isco_dict.keys())].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create query (the jd) and document (isco) lists\n",
    "jd = jobs_ts[jd_colname].to_list()\n",
    "isco_desc = isco['description'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the model\n",
    "model = AutoModel.from_pretrained(\"jinaai/jina-embeddings-v3\", trust_remote_code=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a545e18ac25d4c61831b385125570535",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Encoding:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3aca11e5624c474ebd4618e319a5e9eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Encoding:   0%|          | 0/14 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# load model\n",
    "\n",
    "# Initialize the model\n",
    "model = AutoModel.from_pretrained(\"jinaai/jina-embeddings-v3\", trust_remote_code=True)\n",
    "\n",
    "# # 2. Encode ~ 111 minutes\n",
    "# embeddings_jd = model.encode(jd, task=\"text-matching\", show_progress_bar=True)\n",
    "# embeddings_isco_desc = model.encode(isco_desc, task=\"text-matching\", show_progress_bar=True)\n",
    "# similarity = embeddings_jd @ embeddings_isco_desc.T\n",
    "\n",
    "# 2. Encode ~ 111 minutes\n",
    "embeddings_jd = model.encode(jd, task=\"retrieval.query\", show_progress_bar=True)\n",
    "embeddings_isco_desc = model.encode(isco_desc, task=\"retrieval.passage\", show_progress_bar=True)\n",
    "similarity = embeddings_jd @ embeddings_isco_desc.T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get top n documents\n",
    "top_n = 5\n",
    "\n",
    "indices = np.argsort(similarity)[:, -top_n:]\n",
    "scores = np.take_along_axis(similarity, indices, axis=-1)\n",
    "\n",
    "compiled_topn_codes = []\n",
    "compiled_topn_desc = []\n",
    "for idx in range(len(jd)):\n",
    "    isco_code_topn = [isco['code'][top_idx] for top_idx in indices[idx].tolist()]\n",
    "    isco_desc_topn = [isco['description'][top_idx] for top_idx in indices[idx].tolist()]\n",
    "    compiled_topn_codes.append(isco_code_topn)\n",
    "    compiled_topn_desc.append(isco_desc_topn)\n",
    "    \n",
    "jobs_ts['isco_code'] = [topn_codes[-1] for topn_codes in compiled_topn_codes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg LCA: 0.5952380952380952\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5952380952380952"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def calc_lca(row):\n",
    "    isco1 = row['manual_isco']\n",
    "    isco2 = row['isco_code']\n",
    "    if isco1[0] != isco2[0]:\n",
    "        return 0\n",
    "    elif isco1[1] != isco2[1]:\n",
    "        return 0.25\n",
    "    elif isco1[2] != isco2[2]:\n",
    "        return 0.5\n",
    "    elif isco1[3] != isco2[3]:\n",
    "        return 0.75\n",
    "    else:\n",
    "        return 1\n",
    "\n",
    "def calc_lca_df(df):\n",
    "    eval_df = df[df['id'].astype(str).isin(best_isco_dict.keys())].copy()\n",
    "    eval_df['manual_isco'] = eval_df['id'].astype(str).map(best_isco_dict)\n",
    "    eval_df['lca'] = eval_df.apply(calc_lca, axis=1)\n",
    "    avg_lca = eval_df['lca'].mean()\n",
    "    print(f\"Avg LCA: {avg_lca}\") \n",
    "    return avg_lca\n",
    "\n",
    "calc_lca_df(jobs_ts)  # 0.5357142857142857, 0.5952380952380952"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save out top n descriptions and code\n",
    "with open(\"../output/compiled_topn_desc.json\", 'w') as f:\n",
    "    json.dump(compiled_topn_desc, f) \n",
    "\n",
    "with open(\"../output/compiled_topn_codes.json\", 'w') as f:\n",
    "    json.dump(compiled_topn_codes, f) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cross encoder time: Try 3 diff rerankers, each have their own way of using the reranker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load top n descriptions and code again, if need to split the script into 2 runs\n",
    "with open(\"../output/compiled_topn_desc.json\", 'r') as f:\n",
    "    compiled_topn_desc = json.load(f)\n",
    "    \n",
    "with open(\"../output/compiled_topn_codes.json\", 'r') as f:\n",
    "    compiled_topn_codes = json.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "618e8667e0844ee69bee47d8cedaf59e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/42 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Somehow this is the best way.. using sentence transformers led to constantly increasing ram usage, which slows things\n",
    "# down considerably. ~ 8hrs\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "tqdm.pandas(desc='Cross-encoding in progress')\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    'jinaai/jina-reranker-v2-base-multilingual',\n",
    "    torch_dtype=\"auto\",\n",
    "    trust_remote_code=True,\n",
    ")\n",
    "\n",
    "model.to(\"mps\") \n",
    "model.eval()\n",
    "\n",
    "# The description is the query\n",
    "reranked_isco_codes = []\n",
    "for idx, query in tqdm(enumerate(jd), total=len(jd)):\n",
    "    # rerank the results with original query and documents returned from Chroma\n",
    "    sentence_pairs = [(query, doc) for doc in compiled_topn_desc[idx]]\n",
    "    scores = model.compute_score(sentence_pairs)\n",
    "    # get the isco of the highest scoring document\n",
    "    reranked_isco_codes.append(compiled_topn_codes[idx][np.argmax(scores)])\n",
    "    # To prevent ram from accumulating, could be someting related to MPS\n",
    "    gc.collect()\n",
    "    torch.mps.empty_cache()\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg LCA: 0.7142857142857143\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7142857142857143"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check LCA of reranked dataset\n",
    "def calc_lca(row):\n",
    "    isco1 = row['manual_isco']\n",
    "    isco2 = row['isco_code']\n",
    "    if isco1[0] != isco2[0]:\n",
    "        return 0\n",
    "    elif isco1[1] != isco2[1]:\n",
    "        return 0.25\n",
    "    elif isco1[2] != isco2[2]:\n",
    "        return 0.5\n",
    "    elif isco1[3] != isco2[3]:\n",
    "        return 0.75\n",
    "    else:\n",
    "        return 1\n",
    "\n",
    "def calc_lca_df(df):\n",
    "    eval_df = df[df['id'].astype(str).isin(best_isco_dict.keys())].copy()\n",
    "    eval_df['manual_isco'] = eval_df['id'].astype(str).map(best_isco_dict)\n",
    "    eval_df['lca'] = eval_df.apply(calc_lca, axis=1)\n",
    "    avg_lca = eval_df['lca'].mean()\n",
    "    print(f\"Avg LCA: {avg_lca}\") \n",
    "    return avg_lca\n",
    "\n",
    "jobs_ts_reranked = jobs_ts.copy()\n",
    "jobs_ts_reranked['isco_code'] = reranked_isco_codes\n",
    "calc_lca_df(jobs_ts_reranked) # 0.6964285714285714, 0.7142857142857143"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check gold standard dataset\n",
    "gs_reranked = jobs_ts_reranked[jobs_ts_reranked['id'].astype(str).isin(best_isco_dict.keys())].copy()\n",
    "gs_reranked['manual_isco'] = gs_reranked['id'].astype(str).map(best_isco_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare submission\n",
    "jobs_ts_reranked[['id', 'isco_code']].to_csv('../submission/classification.csv', index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Archive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For msmarco\n",
    "tqdm.pandas(desc='Cross-encoding in progress')\n",
    "model = CrossEncoder(\"cross-encoder/ms-marco-MiniLM-L-12-v2\", max_length=512,\n",
    "                     device=\"mps\")\n",
    "\n",
    "# The description is the query\n",
    "reranked_isco_codes = []\n",
    "for idx, query in tqdm(enumerate(jd), total=len(jd)):\n",
    "    # rerank the results with original query and documents returned from Chroma\n",
    "    sentence_pairs = [(query, doc) for doc in compiled_topn_desc[idx]]\n",
    "    scores = model.predict(sentence_pairs, convert_to_tensor=True).tolist()\n",
    "    # get the isco of the highest scoring document\n",
    "    reranked_isco_codes.append(compiled_topn_codes[idx][np.argmax(scores)])\n",
    "    \n",
    "# check LCA of reranked dataset\n",
    "jobs_ts_reranked = jobs_ts.copy()\n",
    "jobs_ts_reranked['isco_code'] = reranked_isco_codes\n",
    "calc_lca_df(jobs_ts_reranked) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For mxbai\n",
    "tqdm.pandas(desc='Cross-encoding in progress')\n",
    "model = CrossEncoder(\"mixedbread-ai/mxbai-rerank-large-v1\",\n",
    "                      device=\"mps\")\n",
    "\n",
    "# The description is the query\n",
    "reranked_isco_codes = []\n",
    "for idx, query in tqdm(enumerate(jd), total=len(jd)):\n",
    "    # rerank the results with original query and documents\n",
    "    sentence_pairs = [(query, doc) for doc in compiled_topn_desc[idx]]\n",
    "    scores = model.predict(sentence_pairs, convert_to_tensor=True).tolist()\n",
    "    # get the isco of the highest scoring document\n",
    "    reranked_isco_codes.append(compiled_topn_codes[idx][np.argmax(scores)])\n",
    "    \n",
    "    gc.collect()\n",
    "    torch.mps.empty_cache()\n",
    "    \n",
    "# check LCA of reranked dataset\n",
    "jobs_ts_reranked = jobs_ts.copy()\n",
    "jobs_ts_reranked['isco_code'] = reranked_isco_codes\n",
    "calc_lca_df(jobs_ts_reranked) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For BGE\n",
    "from FlagEmbedding import FlagReranker\n",
    "tqdm.pandas(desc='Cross-encoding in progress')\n",
    "reranker = FlagReranker('BAAI/bge-reranker-v2-m3', use_fp16=True) # Setting use_fp16 to True speeds up computation with a slight performance degradation\n",
    "\n",
    "# The description is the query\n",
    "reranked_isco_codes = []\n",
    "for idx, query in tqdm(enumerate(jd), total=len(jd)):\n",
    "    # rerank the results with original query and documents returned from Chroma\n",
    "    sentence_pairs = [[query, doc] for doc in compiled_topn_desc[idx]]\n",
    "    scores = reranker.compute_score(sentence_pairs)\n",
    "    # get the isco of the highest scoring document\n",
    "    reranked_isco_codes.append(compiled_topn_codes[idx][np.argmax(scores)])\n",
    "    \n",
    "# check LCA of reranked dataset\n",
    "jobs_ts_reranked = jobs_ts.copy()\n",
    "jobs_ts_reranked['isco_code'] = reranked_isco_codes\n",
    "calc_lca_df(jobs_ts_reranked)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "es24",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
