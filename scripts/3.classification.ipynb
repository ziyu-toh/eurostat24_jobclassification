{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After cleaning the data, this script does a semantic search based on similarity score using an embedding model, as well as an additional layer of a cross-encoder which helps to perform reranking on a specified top-n number of documents. The cross-encoder is more accurate at predicting similarity scores, at the cost of being more computationally expensive and time consuming because it sends the input data through the entire network, instead of the last layer (which is what happens during inference when using an embedding model).\n",
    "\n",
    "In this case, the queries are the job descriptions, and the documents to be retrieved are the ISCO descriptions + the corresponding codes.\n",
    "\n",
    "The outputs of both script 1 and 2 are used in this script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set file paths: Input is output of 1.data_processing.ipynb\n",
    "jobs_input_path = '../output/jobs_ts_cleaned_simsearch_regex.csv'\n",
    "isco_input_path = '../output/wi_labels_cleaned.csv'\n",
    "compiled_topn_codes_path = '../output/compiled_topn_codes.json' # To output and load top n ISCO codes from the similarity search\n",
    "compiled_topn_desc_path = '../output/compiled_topn_desc.json' # To output and load top n ISCO description from the similarity search\n",
    "submission_path = '../submission/classification.csv' # Need a submission folder as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "jobs_ts = pd.read_csv(jobs_input_path)\n",
    "isco = pd.read_csv(isco_input_path, dtype=str)\n",
    "\n",
    "# Initialise \n",
    "top_n = 5 # Set how many documents you want from initial similarity search filtering, before feeding the top n isco descriptions into the cross-encoder\n",
    "jd_colname = \"title_desc_ts_postclean_regex_simsearch\" \n",
    "device = \"mps\" # For sentence transformers and cross-encoder, device to use. If not using a Macbook with a silicon chip, set this to \"cuda\" if a GPU is available, or \"cpu\" otherwise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create query (the jd) and document (isco) lists\n",
    "jd = jobs_ts[jd_colname].to_list()\n",
    "isco_desc = isco['description'].to_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarity search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# embedding JDs and isco descriptions, and calculating cosine similarity between each JD and all the isco desciptions\n",
    "# Similarity is based on cosine similarity.\n",
    "batch_size=32 # For how many text inputs to embed at the same time\n",
    "model = SentenceTransformer(\"mixedbread-ai/mxbai-embed-large-v1\", trust_remote_code=True,\n",
    "                            revision=\"526dc52cb738085d87002bf00ca4d3d99fd0029b\") \n",
    "\n",
    "embeddings_jd = model.encode(jd, device=device, batch_size=batch_size, show_progress_bar=True, normalize_embeddings=True,\n",
    "                             convert_to_numpy=True)\n",
    "embeddings_isco_desc = model.encode(isco_desc, device=device, batch_size=batch_size, show_progress_bar=True, normalize_embeddings=True,\n",
    "                                    convert_to_numpy=True\n",
    "                                    )\n",
    "similarity = embeddings_jd @ embeddings_isco_desc.T # Embeddings are already normalised, hence this calculates cosine similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get top n documents\n",
    "\n",
    "# This generates the indices of each jd's similarity scores (against the isco descriptions) in ascending order \n",
    "# i.e. last value is the index of the ISCO description has the highest similarity to the given JD\n",
    "indices = np.argsort(similarity)[:, -top_n:] \n",
    "scores = np.take_along_axis(similarity, indices, axis=-1)\n",
    "\n",
    "# For each JD, get the top n codes and description based on the indexes obtained above\n",
    "compiled_topn_codes = []\n",
    "compiled_topn_desc = []\n",
    "for idx in range(len(jd)):\n",
    "    isco_code_topn = [isco['code'][top_idx] for top_idx in indices[idx].tolist()]\n",
    "    isco_desc_topn = [isco['description'][top_idx] for top_idx in indices[idx].tolist()]\n",
    "    compiled_topn_codes.append(isco_code_topn)\n",
    "    compiled_topn_desc.append(isco_desc_topn)\n",
    "    \n",
    "jobs_ts['isco_code'] = [topn_codes[-1] for topn_codes in compiled_topn_codes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save out top n descriptions and code. This is useful in case it is needed to break this script into two parts, if runtimes are too long or \n",
    "# the previous embedding steps took up too much RAM.\n",
    "with open(compiled_topn_desc_path, 'w') as f:\n",
    "    json.dump(compiled_topn_desc, f) \n",
    "\n",
    "with open(compiled_topn_codes_path, 'w') as f:\n",
    "    json.dump(compiled_topn_codes, f) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reranking using cross-encoder: If the similarity search has been previously run in a separate runtime, minimally needs to run all cells before the \"similarity search\" section of this script before proceeding with this part. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load top n descriptions and code again, if need to split the script into 2 runs\n",
    "with open(compiled_topn_desc_path, 'r') as f:\n",
    "    compiled_topn_desc = json.load(f)\n",
    "    \n",
    "with open(compiled_topn_codes_path, 'r') as f:\n",
    "    compiled_topn_codes = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Somehow this is the best way.. using sentence transformers led to constantly increasing ram usage, which slows things\n",
    "# down considerably. ~ 8hrs\n",
    "tqdm.pandas(desc='Cross-encoding in progress')\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    'jinaai/jina-reranker-v2-base-multilingual',\n",
    "    torch_dtype=\"auto\",\n",
    "    trust_remote_code=True,\n",
    "    revision=\"126747772a932960028d9f4dc93bd5d9c4869be4\"\n",
    "    \n",
    ")\n",
    "\n",
    "model.to(device) \n",
    "model.eval()\n",
    "\n",
    "# For each JD, to compare it to the top n most similar ISCO descriptions, and get the isco description which obtained the highest similarity score\n",
    "reranked_isco_codes = []\n",
    "for idx, query in tqdm(enumerate(jd), total=len(jd)):\n",
    "    # Create sentence pairs for each JD and the top ISCO descriptions\n",
    "    sentence_pairs = [(query, doc) for doc in compiled_topn_desc[idx]]\n",
    "    scores = model.compute_score(sentence_pairs)\n",
    "    # get the isco code of the highest scoring document, for submission\n",
    "    reranked_isco_codes.append(compiled_topn_codes[idx][np.argmax(scores)])\n",
    "\n",
    "jobs_ts['isco_code'] = reranked_isco_codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare submission\n",
    "jobs_ts[['id', 'isco_code']].to_csv(submission_path, index=False, header=False) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "es24_final",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
